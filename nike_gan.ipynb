{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms.functional as F\n",
    "import math\n",
    "import itertools\n",
    "import torchvision.utils as vutils\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters:\n",
    "\n",
    "batch_size = 32  # Adjust as needed\n",
    "source_data_path = 'data/source_data'\n",
    "img_size = 128\n",
    "img_channels = 3\n",
    "real_label = 1\n",
    "fake_label = 0\n",
    "\n",
    "# net params\n",
    "latent_dim_values = [1,2,4, 8, 16, 32, 64, 128]\n",
    "d_hidden_values = [64]\n",
    "g_hidden_values = [64]\n",
    "\n",
    "\n",
    "# Define the optimizers\n",
    "lr_gen_values = [0.001, 0.0005, 0.0002, 0.0001, 0.00005]\n",
    "beta1_gen_values = [0.5, 0.9]\n",
    "beta2_gen_values = [0.999]\n",
    "lr_dis_values = [0.001, 0.0005, 0.0002, 0.0001, 0.00005]\n",
    "beta1_dis_values = [0.5, 0.9]\n",
    "beta2_dis_values = [0.999]\n",
    "\n",
    "num_epochs = 5 # Adjust as needed\n",
    "\n",
    "lambda_gp = 0.5\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transform = transforms.Compose([\n",
    "    transforms.Resize((img_size, img_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]) \n",
    "])\n",
    "\n",
    "dataset = ImageFolder(root=source_data_path, transform=data_transform)\n",
    "\n",
    "data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator Network\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_dim, image_channels, img_size, g_hidden):\n",
    "        super(Generator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            # input layer\n",
    "            nn.ConvTranspose2d(latent_dim, g_hidden * 8, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(g_hidden * 8),\n",
    "            nn.ReLU(True),\n",
    "            # 1st hidden layer\n",
    "            nn.ConvTranspose2d(g_hidden * 8, g_hidden * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(g_hidden * 4),\n",
    "            nn.ReLU(True),\n",
    "            # 2nd hidden layer\n",
    "            nn.ConvTranspose2d(g_hidden * 4, g_hidden * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(g_hidden * 2),\n",
    "            nn.ReLU(True),\n",
    "            # 3rd hidden layer\n",
    "            nn.ConvTranspose2d(g_hidden * 2, g_hidden, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(g_hidden),\n",
    "            nn.ReLU(True),\n",
    "            # output layer\n",
    "            nn.ConvTranspose2d(g_hidden, img_channels, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)\n",
    "# Discriminator Network\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, image_channels, img_size, d_hidden):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            # 1st layer\n",
    "            nn.Conv2d(img_channels, d_hidden, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # 2nd layer\n",
    "            nn.Conv2d(d_hidden, d_hidden * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(d_hidden * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # 3rd layer\n",
    "            nn.Conv2d(d_hidden * 2, d_hidden * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(d_hidden * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # 4th layer\n",
    "            nn.Conv2d(d_hidden * 4, d_hidden * 8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(d_hidden * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # output layer\n",
    "            nn.Conv2d(d_hidden * 8, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input).view(-1, 1).squeeze(1)\n",
    "\n",
    "# Generator Network\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_dim, img_channels, img_size, g_hidden):\n",
    "        super(Generator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, img_channels * img_size * img_size),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        return self.model(z)\n",
    "\n",
    "# Discriminator Network\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, img_channels, img_size, d_hidden):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(img_channels * img_size * img_size, 1024),\n",
    "            nn.LeakyReLU(0.01),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.LeakyReLU(0.01),\n",
    "            nn.Linear(512, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gan(n_epochs, latent_dim, lr_gen, beta1_gen, beta2_gen, lr_dis, beta1_dis, beta2_dis, g_hidden, d_hidden,img_channels, img_size):\n",
    "    \n",
    "    # Create GAN\n",
    "    generator = Generator(latent_dim, img_channels, img_size, g_hidden)\n",
    "    generator.apply(weights_init)\n",
    "    discriminator = Discriminator(img_channels, img_size, d_hidden)\n",
    "    discriminator.apply(weights_init)\n",
    "    adversarial_loss = nn.BCELoss()\n",
    "\n",
    "    # noise\n",
    "    viz_noise = torch.randn(batch_size, latent_dim, 1, 1, device=device)\n",
    "\n",
    "    # Move to GPU\n",
    "    generator = generator.to(device)\n",
    "    discriminator = discriminator.to(device)\n",
    "    adversarial_loss = adversarial_loss.to(device)\n",
    "\n",
    "    # Create optimizers for the generator and discriminator\n",
    "    generator_optimizer = optim.Adam(generator.parameters(), lr=lr_gen, betas=(beta1_gen, beta2_gen))\n",
    "    discriminator_optimizer = optim.Adam(discriminator.parameters(), lr=lr_dis, betas=(beta1_dis, beta2_dis))\n",
    "\n",
    "    generator_losses = []\n",
    "    discriminator_losses = []\n",
    "\n",
    "    print_interval = 10\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        for batch_idx, (real_images, _) in enumerate(data_loader):\n",
    "            real_images = real_images.to(device)\n",
    "\n",
    "            # Training the discriminator\n",
    "            discriminator_optimizer.zero_grad()\n",
    "\n",
    "            z = torch.randn(real_images.size(0), latent_dim, device=device)\n",
    "            fake_images = generator(z).view(real_images.size())\n",
    "\n",
    "            real_images_flat = real_images.view(real_images.size(0), -1)\n",
    "            fake_images_flat = fake_images.view(fake_images.size(0), -1)\n",
    "\n",
    "            real_labels = torch.ones(real_images.size(0), 1, device=device) * 0.9  # Label smoothing\n",
    "            fake_labels = torch.zeros(real_images.size(0), 1, device=device)\n",
    "            real_loss = adversarial_loss(discriminator(real_images_flat), real_labels)\n",
    "            fake_loss = adversarial_loss(discriminator(fake_images_flat.detach()), fake_labels)\n",
    "            discriminator_loss = real_loss + fake_loss\n",
    "            \n",
    "\n",
    "\n",
    "            discriminator_loss.backward()\n",
    "            discriminator_optimizer.step()\n",
    "\n",
    "\n",
    "\n",
    "            # Training the generator\n",
    "            generator_optimizer.zero_grad()\n",
    "\n",
    "            z = torch.randn(real_images.size(0), latent_dim, device=device)\n",
    "            fake_images = generator(z).view(real_images.size())\n",
    "\n",
    "            fake_images_flat = fake_images.view(fake_images.size(0), -1)\n",
    "\n",
    "            generator_loss = adversarial_loss(discriminator(fake_images_flat), real_labels)\n",
    "\n",
    "            generator_loss.backward()\n",
    "            generator_optimizer.step()\n",
    "\n",
    "            discriminator_losses.append(discriminator_loss.item())\n",
    "            generator_losses.append(generator_loss.item())\n",
    "\n",
    "            if batch_idx % print_interval == 0:\n",
    "                print(f\"Epoch [{epoch}/{num_epochs}], Batch [{batch_idx}/{len(data_loader)}], \"\n",
    "                      f\"Discriminator Loss: {discriminator_loss.item():.4f}, \"\n",
    "                      f\"Generator Loss: {generator_loss.item():.4f}\")\n",
    "    return discriminator_losses, generator_losses ,generator, discriminator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot loss curves\n",
    "def plot_train_losses(generator_losses, discriminator_losses):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(discriminator_losses, label='Discriminator Loss')\n",
    "    plt.plot(generator_losses, label='Generator Loss')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.title('GAN Training Loss')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_n_image(num_images_to_generate, generator, latent_dim):\n",
    "    generator.eval()\n",
    "    # Generate random noise\n",
    "    z = torch.randn(num_images_to_generate, latent_dim, device=device)\n",
    "    # Generate images using the generator\n",
    "    generated_images = generator(z).view(num_images_to_generate, img_channels, img_size, img_size)\n",
    "\n",
    "    fig, axes = plt.subplots(1, num_images_to_generate, figsize=(15, 3))\n",
    "\n",
    "    for i in range(num_images_to_generate):\n",
    "        img_np = F.to_pil_image(generated_images[i].detach())\n",
    "        axes[i].imshow(img_np)\n",
    "        axes[i].axis('off')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    generator.train()\n",
    "#generate_n_image(5,generator, latent_dim_values[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/5], Batch [0/38], Discriminator Loss: 1.3976, Generator Loss: 1.7852\n",
      "Epoch [0/5], Batch [10/38], Discriminator Loss: 0.7890, Generator Loss: 3.5531\n",
      "Epoch [0/5], Batch [20/38], Discriminator Loss: 0.9192, Generator Loss: 3.4375\n",
      "Epoch [0/5], Batch [30/38], Discriminator Loss: 0.8320, Generator Loss: 2.9094\n",
      "Epoch [1/5], Batch [0/38], Discriminator Loss: 0.8017, Generator Loss: 2.4348\n",
      "Epoch [1/5], Batch [10/38], Discriminator Loss: 1.0712, Generator Loss: 1.4518\n",
      "Epoch [1/5], Batch [20/38], Discriminator Loss: 0.8958, Generator Loss: 1.2222\n",
      "Epoch [1/5], Batch [30/38], Discriminator Loss: 0.9125, Generator Loss: 1.3649\n"
     ]
    }
   ],
   "source": [
    "#latent_dim:  4 lr_gen:  0.001 beta1_gen:  0.5 beta2_gen:  0.999 lr_dis:  0.0002 beta1_dis:  0.5 beta2_dis:  0.999\n",
    "generator_losses, discriminator_losses, generator, discriminator = train_gan(\n",
    "    num_epochs,\n",
    "    latent_dim_values[2],\n",
    "    lr_gen_values[1],\n",
    "    beta1_gen_values[0],\n",
    "    beta2_gen_values[0],\n",
    "    lr_dis_values[2],\n",
    "    beta1_dis_values[0],\n",
    "    beta2_dis_values[0],\n",
    "    g_hidden_values[0],\n",
    "    d_hidden_values[0],\n",
    "    img_channels,\n",
    "    img_size\n",
    ")\n",
    "plot_train_losses(generator_losses, discriminator_losses)\n",
    "generate_n_image(5,generator, latent_dim_values[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hparams_tuning(num_epochs):\n",
    "    res = []\n",
    "    iters = 0\n",
    "    for (latent_dim, lr_gen, beta1_gen, beta2_gen, lr_dis, beta1_dis, beta2_dis, g_hidden, d_hidden) in itertools.product(\n",
    "        latent_dim_values, lr_gen_values, beta1_gen_values, beta2_gen_values,\n",
    "        lr_dis_values, beta1_dis_values, beta2_dis_values, g_hidden_values, d_hidden_values):\n",
    "        print('--------------- iteration: ', iters, '-----------------')\n",
    "        print('latent_dim: ', latent_dim, 'lr_gen: ', lr_gen, 'beta1_gen: ', beta1_gen, 'beta2_gen: ', beta2_gen, 'lr_dis: ', lr_dis, 'beta1_dis: ', beta1_dis, 'beta2_dis: ', beta2_dis)\n",
    "        print('------------------------------------------------------')\n",
    "        generator_losses, discriminator_losses, generator, discriminator = train_gan(num_epochs, latent_dim, lr_gen, beta1_gen, beta2_gen, lr_dis, beta1_dis, beta2_dis, g_hidden, d_hidden, img_channels, img_size)\n",
    "        generate_n_image(5,generator, latent_dim)\n",
    "        plot_train_losses(generator_losses, discriminator_losses)\n",
    "        res.append((generator_losses, discriminator_losses, generator, discriminator))\n",
    "        iters = iters +1\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "a = hparams_tuning(num_epochs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
